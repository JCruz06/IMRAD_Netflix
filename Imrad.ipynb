{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a786ee6-c995-4dab-a9f1-a98abd71a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22dc08b-dd8a-4a58-a0bc-12e2ba4b38e8",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ef9186c-f84d-4e8c-a690-bcc6372c8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv('data/netflix_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b83d1adf-95c4-4ed0-b6d1-864538ff356d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8807 entries, 0 to 8806\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   show_id       8807 non-null   object\n",
      " 1   type          8807 non-null   object\n",
      " 2   title         8807 non-null   object\n",
      " 3   director      6173 non-null   object\n",
      " 4   cast          7982 non-null   object\n",
      " 5   country       7976 non-null   object\n",
      " 6   date_added    8797 non-null   object\n",
      " 7   release_year  8807 non-null   int64 \n",
      " 8   rating        8803 non-null   object\n",
      " 9   duration      8804 non-null   object\n",
      " 10  listed_in     8807 non-null   object\n",
      " 11  description   8807 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 825.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show info about Dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "542e3c79-334d-4130-8d0b-b202b33e2f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_id            0\n",
       "type               0\n",
       "title              0\n",
       "director        2634\n",
       "cast             825\n",
       "country          831\n",
       "date_added        10\n",
       "release_year       0\n",
       "rating             4\n",
       "duration           3\n",
       "listed_in          0\n",
       "description        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of Missing Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25f6ea-c844-42f2-bf2d-cf2030f74878",
   "metadata": {},
   "source": [
    "### Filling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa82a2c-e13b-4f62-b297-1254ae3e8eda",
   "metadata": {},
   "source": [
    "Used **mode** approach for filling missing values on columns <code>(rating and duration)</code> because they are categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d4ddf7e6-02a9-4b68-85b1-7dc2e20ca960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jester\\AppData\\Local\\Temp\\ipykernel_3504\\3182794350.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['director'].fillna('Unknown Director', inplace=True)\n",
      "C:\\Users\\Jester\\AppData\\Local\\Temp\\ipykernel_3504\\3182794350.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['cast'].fillna('Unknown Cast', inplace=True)\n",
      "C:\\Users\\Jester\\AppData\\Local\\Temp\\ipykernel_3504\\3182794350.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['country'].fillna('Unknown Country', inplace=True)\n",
      "C:\\Users\\Jester\\AppData\\Local\\Temp\\ipykernel_3504\\3182794350.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['date_added'].fillna('Unknown date', inplace=True)\n",
      "C:\\Users\\Jester\\AppData\\Local\\Temp\\ipykernel_3504\\3182794350.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['rating'].fillna(df['rating'].mode()[0], inplace=True)\n",
      "C:\\Users\\Jester\\AppData\\Local\\Temp\\ipykernel_3504\\3182794350.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['duration'].fillna(df['duration'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['director'].fillna('Unknown Director', inplace=True)\n",
    "df['cast'].fillna('Unknown Cast', inplace=True)\n",
    "df['country'].fillna('Unknown Country', inplace=True)\n",
    "df['date_added'].fillna('Unknown date', inplace=True)\n",
    "df['rating'].fillna(df['rating'].mode()[0], inplace=True)\n",
    "df['duration'].fillna(df['duration'].mode()[0], inplace=True)\n",
    "\n",
    "# Save the cleaned csv file\n",
    "new_file_path = 'data/cleaned_netflix_titles.csv'\n",
    "df.to_csv(new_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b072572-ad1d-4f8b-a882-6c9d0ed84180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8807 entries, 0 to 8806\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   show_id       8807 non-null   object\n",
      " 1   type          8807 non-null   object\n",
      " 2   title         8807 non-null   object\n",
      " 3   director      8807 non-null   object\n",
      " 4   cast          8807 non-null   object\n",
      " 5   country       8807 non-null   object\n",
      " 6   date_added    8807 non-null   object\n",
      " 7   release_year  8807 non-null   int64 \n",
      " 8   rating        8807 non-null   object\n",
      " 9   duration      8807 non-null   object\n",
      " 10  listed_in     8807 non-null   object\n",
      " 11  description   8807 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 825.8+ KB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/cleaned_netflix_titles.csv'\n",
    "cleaned_df = pd.read_csv(file_path)\n",
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbaa87-c9b6-4cce-9755-cb3efc3b1dff",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a991f70d-53d4-4ee8-b6f7-1a8f42d56a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "preprocessed_df = pd.read_csv('data/cleaned_netflix_titles.csv')\n",
    "\n",
    "# Convert the 'duration' column to numerical format\n",
    "preprocessed_df['duration'] = preprocessed_df['duration'].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Normalize the 'duration' column\n",
    "scaler = MinMaxScaler()\n",
    "preprocessed_df['duration'] = scaler.fit_transform(preprocessed_df[['duration']])\n",
    "\n",
    "# One-hot encode categorical variables (including genre if needed)\n",
    "preprocessed_df = pd.get_dummies(preprocessed_df, columns=['country', 'listed_in'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "caffd699-ed4f-400c-ab37-e3ead095267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (7045, 1264)\n",
      "Testing set shape: (1762, 1264)\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = preprocessed_df.drop(columns=['rating', 'show_id', 'title', 'director', 'cast', 'date_added', 'description'])\n",
    "y = preprocessed_df['rating']\n",
    "\n",
    "# Convert target variable to categorical\n",
    "y = pd.factorize(y)[0]  # Convert ratings to numerical values\n",
    "y = to_categorical(y)    # One-hot encode the target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Checking the shape\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f20a67-217a-4ede-8996-fc6549c2cac5",
   "metadata": {},
   "source": [
    "### Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff2c56e-6914-476b-a933-c06e84b9189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the neural network model\n",
    "def build_model(input_shape, num_classes, layers=2, neurons=64, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(Dense(neurons, input_shape=(input_shape,), activation='relu'))  # First hidden layer\n",
    "    \n",
    "    # Additional hidden layers\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))  # Hidden layers with ReLU activation\n",
    "    \n",
    "    # Output layer (softmax for multi-class classification)\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile the model with the specified optimizer\n",
    "    if optimizer == 'adam':\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    elif optimizer == 'sgd':\n",
    "        model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    else:\n",
    "        raise ValueError(\"Optimizer not supported. Use 'adam' or 'sgd'.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20987017-3953-452c-89b2-49c105cf50a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jester\\anaconda3\\envs\\newenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Movie'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], layers\u001b[38;5;241m=\u001b[39mnum_layers, \n\u001b[0;32m     10\u001b[0m                     neurons\u001b[38;5;241m=\u001b[39mneurons_per_layer, optimizer\u001b[38;5;241m=\u001b[39moptimizer_choice)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluate the model performance\u001b[39;00m\n\u001b[0;32m     16\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newenv\\Lib\\site-packages\\optree\\ops.py:747\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    745\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    746\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treespec\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;28mmap\u001b[39m(func, \u001b[38;5;241m*\u001b[39mflat_args))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newenv\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newenv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newenv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newenv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newenv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newenv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newenv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Movie'"
     ]
    }
   ],
   "source": [
    "# Specify hyperparameters\n",
    "num_layers = 3           # Number of hidden layers\n",
    "neurons_per_layer = 128  # Number of neurons in each hidden layer\n",
    "optimizer_choice = 'adam'  # Optimizer to use\n",
    "epochs = 50              # Number of epochs for training\n",
    "batch_size = 32          # Batch size for training\n",
    "\n",
    "# Build the model\n",
    "model = build_model(X_train.shape[1], y_train.shape[1], layers=num_layers, \n",
    "                    neurons=neurons_per_layer, optimizer=optimizer_choice)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model performance\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a7b7e-0587-4364-8279-f2c7af7934b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
